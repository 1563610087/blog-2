{"./":{"url":"./","title":"简介","keywords":"","body":" 简介 芳华正茂始少年，时光正好，未来可期 ！ 技术为主，读书笔记、随笔、理财为辅，做个终身学习者。 收获不止技术，还有财富。 分类 JavaScript 数据结构与算法之美 JavaScript Vue.js ES 6 React.js Node.js MongoDB 软技能 硬核面试专题 前端工程师成长之路 半小时硬核理财入门 随笔 文章 | 软技能 1. GitHub 上能挖矿的神仙技巧 - 如何发现优秀开源项目 2. GitHub 吸星大法 - 一年收获 2000+ Star 的心得 | 前端工程师的成长之路 1. 2018 年，我的本命年 - 前端工作师的年终总结 2. 前端架构师亲述：前端工程师成长之路的 N 问 及 回答 | 随笔 1. 程序员不止眼前的逻辑和代码，还应有健康的体魄和精气神 | JavaScript 数据结构与算法之美 1. JavaScript 数据结构与算法之美 - 时间和空间复杂度 2. JavaScript 数据结构与算法之美 - 线性表（数组、队列、栈、链表） 3. JavaScript 数据结构与算法之美 - 实现一个前端路由，如何实现浏览器的前进与后退 ？ 4. JavaScript 数据结构与算法之美 - 栈内存与堆内存 、浅拷贝与深拷贝 5. JavaScript 数据结构与算法之美 - 递归 6. JavaScript 数据结构与算法之美 - 非线性表（树、堆） 7. JavaScript 数据结构与算法之美 - 冒泡排序、选择排序、插入排序 8. JavaScript 数据结构与算法之美 - 归并排序、快速排序、希尔排序、堆排序 9. JavaScript 数据结构与算法之美 - 计数排序、桶排序、基数排序 10. JavaScript 数据结构与算法之美 - 十大经典排序算法汇总 11. JavaScript 数据结构与算法之美 - 强烈推荐 GitHub 上值得前端学习的数据结构与算法项目 | 前端硬核面试专题 1. 2019 前端秋季社招面试经历总结（二年多经验） | Vue.js 1. 一张思维导图辅助你深入了解 Vue | Vue-Router | Vuex 源码架构(文字版) 2. 一张思维导图辅助你深入了解 Vue | Vue-Router | Vuex 源码架构 3. Vue + TypeScript + Element 搭建简洁时尚的博客网站及踩坑记 4. vue-cli3.x 新特性及踩坑记 5. 基于 vue+mint-ui 的 mobile-h5 的项目说明 6. 复杂表格设计数据格式 | React.js 1. github 授权登录教程与如何设计第三方授权登录的用户表 2. 项目文档说明：react + Ant Design 的 blog-react-admin 3. react + Ant Design + 支持 markdown 的 blog-react 项目的文档说明 4. react + node + express + ant + mongodb 的简洁兼时尚的博客网站 | ES 6 1. 那些必会用到的 ES6 精粹 | JavaScript 1. 前端解决第三方图片防盗链的办法 - html referrer 访问图片资源 403 问题 2. 原生 js 实现一个有动画效果的进度条插件 progress 3. 原生 js 实现一个前端路由 router 4. js 实现上下改变父 div 的高度，左右上下动态分割孩子的宽高 5. js 日期对象 setMonth 的锅 6. 细数 JavaScript 实用黑科技(二) 7. 细数 JavaScript 实用黑科技(一) 8. 面试题之从敲入 URL 到浏览器渲染完成 9. JS 是单线程，你了解其运行机制吗 ？ 10. js 递归调用 11. WebKit 技术内幕之浏览器与 WebKit 内核 | Node.js 1. 基于 node express mongodb 的 blog-node 项目文档说明 2. 服务器小白的我，是如何将 node+mongodb 项目部署在服务器上并进行性能优化的 | 性能优化 1. 一次网站的性能优化之路 -- 天下武功，唯快不破 | 半小时硬核理财入门 1. 用钱生钱，从掌握金钱的规律开始 精彩待续 ... | 学习资源 极客时间上的《TypeScript 开发实战》课程资源，包含课件、思维导图、课程源代码 计划 以下是笔者往后的计划，计划执行的先后顺序，视情况而定。 | webpack 原理及源码分析 精彩待续 ... | Vue 原理及源码分析 精彩待续 ... | TypeScript 入门到熟练 1. Vue + TypeScript + Element 搭建简洁时尚的博客网站及踩坑记 精彩待续 ... | 小程序入门到熟练 精彩待续 ... | Flutter 入门到熟练 精彩待续 ... | 翻译国外文章 精彩待续 ... 社区 GitHub 掘金 知乎 SegmentFault 简书 --> 撩我 微信：CB834301747，加我时的验证申请，请输入暗号哦。 暗号是：夜尽天明 ，不然不给通过哦（非诚勿扰）。 邮箱：2993806084#qq.com ，将 # 号换成 @ 即可。 有什么问题，直接发邮件到我邮箱就可以，有必要的，我都会给您回复邮件的。 BB 文章版权为夜尽天明所有，未经允许，不得转载；如要转载文章，请联系笔者。 如果你觉得该项目不错，或者对你有所帮助，点个 Star 、或者真心赞赏一下 都是对我最大的鼓励，我会更有动力维护好该项目。 江山父老能容我，不使人间造孽钱。 Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 20:58:55 "},"github-follow.html":{"url":"github-follow.html","title":"GitHub 吸星大法","keywords":"","body":" 1. 前言 本文介绍如何在 GitHub 上发现优秀的开源项目，找到你想要的矿。 GitHub 作为全球最大的同性交友网站，也是矿资源非常丰富的矿场。 GitHub 有时比 Google 还有用，如果你不懂如何使用它来挖矿，那你不算一名合格的程序员。 GitHub 是一个宝藏库，可没有藏宝图，GitHub 这个亿计的优秀的开源项目也和你没有关系。 一般人没事的时候刷刷朋友圈、微博、电视剧、知乎，而有些人是没事的时候刷刷 GitHub ，看看最近有哪些流行的项目，久而久之，这差距就越来越大，那么如何发现优秀的开源项目呢 ？ 笔者做前端开发这些年，几乎每天都会刷 GitHub，也算是 GitHub 的重度使用者了，其中也掌握了一定的技巧，由此写一下我是如何使用它来挖矿的 ！ 笔者博客地址：GitHub。 2. Follow 关注 GitHub 上活跃的大牛。 GitHub 主页有一个类似微信的朋友圈，所有你关注的人（相当于微信的好友）的动作，比如 create、star、fork 了某个项目都会出现在你的时间线上，这种方式适合我这种比较懒的人，不用主动去找项目，而这种基本是我每天获取信息的一个很重要的方式。 一些大牛 create、star、fork 了某个项目，很大程度是因为该项目做的好，或者对他有用的。 比如：github 上的 actions 功能刚出不是很久，很多人还不会用，然后阮玉峰老师今天就创建了一个 github-actions-demo 的仓库。 再比如：还有过几天就是中秋了，所以很多人抢票回家，所以不少人 star 了 12306 的智能刷票，订票的项目。 比如下图就是我关注的一些大牛在今天点了 Star 的项目。 不知道怎么关注这些人？那么很简单，关注我 biaochenxuying ，以及我 GitHub 上关注的一些大牛，基本就差不多了，因为我关注的很多在 GitHub 上活跃的大牛，平时看到活跃的大牛也会继续关注。 可能很多人不想 Follow 别人，因为不想被别人看到，不想承认别人比自己优秀。 但我想说：承认别人比自己优秀不丢脸。 Vue.js 的作者尤雨溪够牛 B 吧，都关注了不少大牛呢，都虚心向别人学习呢，更何况我们呢。 活跃是指：经常在 GitHub 上做开源项目、 Star 别人优秀项目、Fork 别人优秀项目、Follow 别人、或者写博客。 但是你关注太多比你的 level 高太多的大牛用处不是很大的，往往对你现在的帮助不是很大，所以关注顶级大牛的目的应该是更好的知道行业的动态或者方向。 多关注一些 level 高一两级的大牛，比如你是初级前端，那你应该关注多一些中级或者高级的前端， 只比你的 level 高一两级的前端现在关注的内容或者知识往往是你即将要学到或者用到的。 至于为什么只关注活跃的大牛呢，因为自己能从他那里有所收获，如果某个技术大牛确实很厉害，但是对你没什么帮助，关注 TA 有个毛用嘛！ 3. Explore Repositories github 也会推一些你可能感兴趣的仓库给你的，只要你一打开 github.com 网站，就出现了。比如下图是今天推送给我的仓库。 4. Explore 4.1 Trending Trending：趋势的意思。 在 Trending 页面，你可以看到最近一些热门的开源项目或者开发者，这个页面可以算是很多人主动获取一些开源项目和活跃开发者最好的途径。 首先点击 Explore => Trending。 可以选择看开源项目还是开发者，切换 Repositories 和 Developers 即可。 可以选择「当天热门」、「一周之内热门」和「一月之内热门」来查看。 可以选择语言类来查看，比如你想查看最近热门的 Vue 项目，那么右边就可以选择 Vue 语言。 这个页面推荐大家每隔几天就去看下，主动发掘一些优秀的开源项目。 4.2 Topics Topics 里面也可以看某个话题或者领域内最优秀的项目。 比如前端领域： Front end 5. Star 因为笔者也做过几个开源项目，所以知道 star 数会给作者动力的，越多人点 star ，维护这个开源项目的驱动力就越足。 笔者经常看到不错的、有趣的、有用的，或者现在没用，以后会用到的优秀开源项目，都会 star 一下，当是给这个开源的作者一份鼓励，希望 TA 更好的维护这个开源项目，以后用到的时候可以在 star 过的项目里面找出来。 笔者不想 fork 别人的项目，除非想深入研究该项目的源码才会 fork。 别人是把 fork 当收藏，而我把是 star 当收藏，把 fork 当研究。 所以你也可以在某些大牛的 star 列表里面找优秀开源项目，比如笔者就 star 了不少优秀的开源项目，如下图。 如果你在笔者的 star 列表 里面找的话，你应该会有惊喜，你会发现很多有趣实用的项目的。 因为笔者 star 过前端学习、教程、免费电子书、工具、资源、面试、Git 的奇技淫巧、有趣实用的项目等等。 比如： 油猴脚本 一个脚本搞定百度网盘下载 总结关于科学上网的概念方法及工具 6. Search 除了平时主动发现优秀开源项目之外，主动搜索又是非常重要的技能，很多百度或者 google 不到的东西，在 github 上都能找到。 输入搜索关键字，可以选择排序的方式、语言、仓库。 7. 总结 GitHub 上优秀开源项目真的是一大堆，授人以鱼不如授人以渔，请大家自行主动发掘自己需要的开源项目吧，不管是应用在实际项目上，还是对源码的学习，都是提升自己工作效率与技能的很重要的一个渠道，总有一天，你会突然意识到，原来不知不觉你已经走了这么远！ 笔者博客地址：GitHub 觉得不错，不妨随手转发、点赞，都是对我这个良心笔者莫大的鼓励！ 参考文章：从 0 开始学习 GitHub 系列之「如何发现优秀的开源项目？」 Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 22:25:53 "},"github-star.html":{"url":"github-star.html","title":"GitHub 挖宝技巧","keywords":"","body":" 1. 前言 笔者做前端开发这些年，几乎每天都会刷 GitHub，也时不时在上面分享博客和做一些开源项目，也算是 GitHub 的重度使用者了，其中也掌握了一定的技巧，并在一年内收获了 2000+ Star。 因为有读者问过我，想知道我在 GitHub 上做开源项目并获得 2000+ Star 的心得，所以笔者在此分享一下这过程的一些经验与心得，算是给那些关注了我的读者的福利。 2. 为什么要经营好你的 GitHub ？ GitHub 可以说是你的技术名片，你在 GitHub 的贡献可以作为简历的加分项。 据我所知，对于技术岗位，猎头在找候选人的诸多方法中，有一条就是通过 GitHub 来找技术比较好的候选人的，如果你的 GitHub 经营得很好，开源项目收获的 Star 比较多，一般都会为你提供一些好的机会。 为什么笔者知道 ？因为 ta 们找过笔者，所以我知道，哈哈哈。 而且如果某个公司的团队负责人看到你的 GitHub，觉得你的技术不错，也会给你抛来招揽的橄榄枝。这种情况，笔者也遇到过，哈哈哈。 笔者也是最近裸辞并换了工作，最近在找工作过程中，笔者知道了：想通过社招获得好工作或者进大厂，一般都要有如下 4 点中的 1 - 2 个亮点才行。 高学历，名校毕业 工作年限足，经验丰富（但不是 1 年经验当 5 年用那种） 有开源与影响力，GitHub 的贡献或者经常写优质博客 本身就有大厂的工作经历 大多数人都是普通人，平时所做工作几乎都是写业务而已，那么只有你具备 1 - 2 个亮点，HR 或者面试官 在筛选简历时，才会选中你，或者好机会才会自动找上你。 找工作时，我简历中的亮点就是 GitHub 的贡献，在开源与影响力的一栏中，我是这样写的： 开源与影响力 GitHub： https://github.com/biaochenxuying 。 本人有 写技术博客和做开源项目 的习惯，乐于分享，坚持写博客和做开源项目的时间长达 一年半。 利用业余时间开源和维护了 10 个个人项目，有 博客文章、Vue 源码的思维导图、Vue 版的博客网站前台、React 管理后台、Express 后台、还有一些 js 轮子。 GitHub 上总共收获 2000+ Star，500+ Fork ，570+ Followers；超过 100 star 的项目有 6 个，超过 500 star 的项目有 1 个。 如果没有这个亮点，估计在这互联网寒冬期间，笔者也很难有好公司的面试机会或者找到工作啊。 3. 如何经营好你的 GitHub ? 你能为他人提供什么样的价值。 想收获到很多小星星，那你首先要想的是：你能为他人提供什么样的价值。 就笔者来说，笔者在 GitHub 上为他人提供的价值有： 写的博客文章，他人可以从中吸取到 经验、知识点，或者思维得到提升； 把相关知识总结成思维导图，分享出来，他人可以直接学习； 把根据自己的兴趣，做了个博客网站，并把源码分享出来，并做了开源，别人可以直接用； 自己工作中造的一些轮子，也分享出来，他人可以直接用。 总之，原则就是：你能提供的价值越大越多，收获到的小星星就会越多。 3.1 写博客文章 至于为什么要写博客，我就不说了，很多大神已经写过了，可以参考一下几个大佬们写的 我为什么要写博客 ？ 笔者只想说，只要你开始了写博客之路，那基本就是一条一去不回头的路了。因为笔者就是这样，而且我看到很多写博客的人也是这样。 还有就是最好用 markdown 语法来写作，也可以参考阮一峰写的 中文技术文档的写作规范，这样可以更加关注内容本身，而不是样式，多个平台也可以发布。 而且写作这是非常重要的一环，因为后面介绍的方法，多多少少都依赖于写作。 笔者专门在 GitHub 上创建了一个 blog 仓库来写文章的，也是目前笔者收获最多 Star 的开源项目，而且布局和风格什么的，都是比较正规的。如果你也想创建个仓库专门来写文章的，可以参考我这个 blog 项目。 3.2 做开源项目 可能你觉得自己的代码写的不好，没有什么流弊的功能，不敢开源代码之类的，这想法也没错，但你要知道，大神都是从小白过来的，每个人都有是小白的时候。 而且后来者从来都不缺，很多时候，你的分享主要是对那些后来者有用而已；更何况，比你厉害的人可能会指出你分享中的错误或者改进的地方，也是能促进你的进步的。 这个开源项目类型可以是很多种的，有造轮子的、写插件的、高仿某个 app 或者网站的、用某些技术写个通用模版的、总结知识做成思维导图的、提供某个功能的 等等。 虽然类型那么多，最主要的是：要根据自身的兴趣和平时日常工作来选择要做哪种类型的开源项目。 笔者因为平时有写博客，所以想做个自己的个人网站，专门来展示自己的文章的，而且当时想学习 react 和 node ，所以做了个网站的项目并开源了，包含 前台展示、管理后台、后台。 还有一些开源项目是笔者在工作中造的轮子或者插件（ps：如果是公司的机密项目的轮子、插件之类，又或者公司声明了不能把代码外传的，不要随意开源哦）。 我是这样想的：既然自己有这样的需求（比如：做个自己的个人网站需求），那么同理，其他人可能也有这个需求的，所以我做好功能并开源，对他人就可能有帮助。 我开源了之后，也的确给不少人提供了经验或者帮助，因为这个项目，笔者收获了很多的小星星。而且很多人是伸手党来的，你做好了，别人可以直接用，多方便啊。 还有一个项目就是 vue + typescript 版的博客前台展示，当时我已经写了一版 react 版的前台展示了，为什么还写一版 vue 版的呢 ？因为我想学习 typescirpt，所以想在结合 vue 来实践一下，而工作中还没用得上，所以又把我的网站前台展示用 vue + typescript 用了一版。 而且当时 typescript 加 vue 的开源项目还很少的，连相关的博客都少，我想参考一下别人的项目，但是没有啊，所以当时也踩了很多坑。所以我想：我如果开源了的话，肯定很多人会参考我这个项目的，也会带来一定的流量，所以能收获不少的 star 。也的确是这样，这个项目也是我目前的完整项目中最多 star 的一个。 有一点要注意的是：一个人的精力与业余时间是非常有限的。如果是一个人的话，做的开源项目不要太多吧，维护好一个开源项目是很需要时间的，维护多个项目所需要的时间就更多了。 你以为开源了就行了吗 ？太天真了。 那要写 README.md 来介绍你开源的项目的，比如一般要有如下内容： 简介：简单说明一下这个项目是干嘛的 结果：这个项目的代码达到了什么效果 步骤：怎么运行你这个项目，或者怎么使用你写的插件。 文章：详细讲解这个项目（可无，最好有） 有了这个 README.md 之后，别人一看到你的项目的 github 就知道这个项目的情况了。 3.3 硬核为王 以做好一个伟大的产品的心态来做开源项目。 做开源项目说白了就是做一个产品，我们要以做好一个产品的心态来做开源项目，这样你的产品质量才会更优，才会够硬核，也就是有料。 我做这个博客网站的时候是有这个意识的，做完第一版之后，也在不断的迭代和完善。 就我做成的成果来看，其实还不够硬核，因为还有一些优化的点和实用的功能的，只是我还没做。 目前，笔者比较遗憾的是：还没有一个达到 1000+ Star、甚至 10000+ Star 的硬核开源项目。以后技术更精进了，或者有好想法了，再开源一个好的开源项目吧。 我知道的一个比较硬核的开源项目是这个：支持自定义样式的 Markdown 编辑器，这个项目就是以一个产品的理念来做的，作者也在不断的迭代和完善。而且更新的速度很快，也很规范。 当然你也可以参考那些做得很出名的开源项目，毕竟做得那么成功，肯定有其原因。 3.4 时间与坚持 做开源项目是很需要时间的。 比如笔者做的博客网站项目就用了 2 个多月的业余时间来做，还好公司的正常的上班时间是 965 的，平时上班只需要 7 个钟，加班的情况比较少，所以业余时间比较多。 但利用业余时间做开源项目时，我的每天真实工作时间可以说是 9117 或者 907，因为晚上下班了，我都会用 2 - 3 个钟来做开源项目，周末的两天也是这样，而且周一到周五的中午吃完饭时，我也会挤出大概 30 - 40 分钟的时候来学习相关的技术，或者做开源项目。 这样习惯了大概两个月之后，终于把网站的第一版撸了出来。 所以时间很重要，没有时间你就做不出好的开源项目。 而且这是一直坚持的结果，如果中途觉得累了，可能就放弃了。 如果你问我难道不觉得累吗，其实我很少觉得累，因为是做自己喜欢的事，兴致比较高，再加上平时有锻炼身体，所以不累。 当然，如果你的工作时间是 996 的，可能没那么多时间了，最好是开源一些工作中开发好的插件或者特定功能的轮子之类的。 3.5 推广自己的项目 有才华很重要，让别人知道你的才华更重要。 酒好也怕巷子深。 当你做好你的开源项目之后，你以为就会有人给你小星星了，那你就太天真了。 想收获小星星，还要自己去技术社区推广的，不然没人知道你的项目，现在这个时代，流量为王，这一点对于开源项目也是一样的，人来了，了解到你的项目，才有可能给你小星星。 而且要推广就要脸皮厚，这叫做自我营销。 所以要写文章介绍你的开源项目，文章的要点主要是突出 效果与功能。 然后就是 宣传 了，到各大技术社区（比如：思否、掘金 等）去发布你的文章，达到引流的目的。 如果想知道怎么写推广的文章，可以参考我写的这两篇文章： react + node + express + ant + mongodb 的简洁兼时尚的博客网站 和 Vue + TypeScript + Element 项目实践(简洁时尚博客网站)及踩坑记。 4. 总结 笔者觉得想做好开源项目，最重要因素是兴趣，不然你可能中途就放弃了，很难坚持到把项目做完和做好。 有时候，有很强的功利心（比如 为了钱、为了名）也是好事，这可是你的一大助力，是可以推动你做完你想做的事的。 最后，要掌握 GitHub 吸星大法，先从写作开始，从现在开始。 推荐阅读： GitHub 上能挖矿的神仙技巧 - 如何发现优秀开源项目，估计很多人都不知道的技巧，甚至很多高级工程师都不知道。 你说你爱学习，且连一台属于自己的服务器都没有：全栈君觉得每个开发者都应该拥有自己的网站和服务器，这可是很酷的事情，学习 Linux、跑跑脚本、建站、搭博客啥的都行，现在阿里云的服务器只需要 86元 一年，优惠只剩下最后一天了。 Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 22:25:28 "},"js-time-space.html":{"url":"js-time-space.html","title":"时间和空间复杂度","keywords":"","body":" 复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半了。 1. 什么是复杂度分析 ？ 数据结构和算法解决是 “如何让计算机更快时间、更省空间的解决问题”。 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。 2. 为什么要进行复杂度分析 ？ 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。 3. 如何进行复杂度分析 ？ 3.1 大 O 表示法 算法的执行时间与每行代码的执行次数成正比，用 T(n) = O(f(n)) 表示，其中 T(n) 表示算法执行总时间，f(n) 表示每行代码执行总次数，而 n 往往表示数据的规模。这就是大 O 时间复杂度表示法。 3.2 时间复杂度 1）定义 算法的时间复杂度，也就是算法的时间量度。 大 O 时间复杂度表示法 实际上并不具体表示代码真正的执行时间，而是表示 代码执行时间随数据规模增长的变化趋势，所以也叫 渐进时间复杂度，简称 时间复杂度（asymptotic time complexity）。 例子1： function aFun() { console.log(\"Hello, World!\"); // 需要执行 1 次 return 0; // 需要执行 1 次 } 那么这个方法需要执行 2 次运算。 例子 2： function bFun(n) { for(let i = 0; i 那么这个方法需要执行 ( n + 1 + n + 1 ) = 2n +2 次运算。 例子 3： function cal(n) { let sum = 0; // 1 次 let i = 1; // 1 次 let j = 1; // 1 次 for (; i 注意，这里是二层 for 循环，所以第二层执行的是 n * n = n2 次，而且这里的循环是 ++i，和例子 2 的是 i++，是不同的，是先加与后加的区别。 那么这个方法需要执行 ( n2 + n2 + n + n + 1 + 1 +1 ) = 2n2 +2n + 3 。 2）特点 以时间复杂度为例，由于 时间复杂度 描述的是算法执行时间与数据规模的 增长变化趋势，所以 常量、低阶、系数 实际上对这种增长趋势不产生决定性影响，所以在做时间复杂度分析时 忽略 这些项。 所以，上面例子1 的时间复杂度为 T(n) = O(1)，例子2 的时间复杂度为 T(n) = O(n)，例子3 的时间复杂度为 T(n) = O(n2)。 3.3 时间复杂度分析 只关注循环执行次数最多的一段代码 单段代码看高频：比如循环。 function cal(n) { let sum = 0; let i = 1; for (; i 执行次数最多的是 for 循环及里面的代码，执行了 n 次，所以时间复杂度为 O(n)。 加法法则：总复杂度等于量级最大的那段代码的复杂度 多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 function cal(n) { let sum_1 = 0; let p = 1; for (; p 上面代码分为三部分，分别求 sum_1、sum_2、sum_3 ，主要看循环部分。 第一部分，求 sum_1 ，明确知道执行了 100 次，而和 n 的规模无关，是个常量的执行时间，不能反映增长变化趋势，所以时间复杂度为 O(1)。 第二和第三部分，求 sum_2 和 sum_3 ，时间复杂度是和 n 的规模有关的，为别为 O(n) 和 O(n2)。 所以，取三段代码的最大量级，上面例子的最终的时间复杂度为 O(n2)。 同理类推，如果有 3 层 for 循环，那么时间复杂度为 O(n3)，4 层就是 O(n4)。 所以，总的时间复杂度就等于量级最大的那段代码的时间复杂度。 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积 嵌套代码求乘积：比如递归、多重循环等。 function cal(n) { let ret = 0; let i = 1; for (; i 方法 cal 循环里面调用 f 方法，而 f 方法里面也有循环。 所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) T2(n) = O(nn) = O(n2) 。 多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加 function cal(m, n) { let sum_1 = 0; let i = 1; for (; i 以上代码也是求和 ，求 sum_1 的数据规模为 m、求 sum_2 的数据规模为 n，所以时间复杂度为 O(m+n)。 公式：T1(m) + T2(n) = O(f(m) + g(n)) 。 多个规模求乘法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相乘 function cal(m, n) { let sum_3 = 0; let i = 1; let j = 1; for (; i 以上代码也是求和，两层 for 循环 ，求 sum_3 的数据规模为 m 和 n，所以时间复杂度为 O(m*n)。 公式：T1(m) T2(n) = O(f(m) g(n)) 。 3.4 常用的时间复杂度分析 多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。 包括 O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n2) （平方阶）、O(n3)（立方阶）。 除了 O(logn)、O(nlogn) ，其他的都可从上面的几个例子中看到。 下面举例说明 O(logn)（对数阶）： let i=1; while (i 代码是从 1 开始，每次循环就乘以 2，当大于 n 时，循环结束。 其实就是高中学过的等比数列，i 的取值就是一个等比数列。在数学里面是这样子的： 20 21 22 ... 2k ... 2x = n 所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了，通过 2x = n 求解 x，数学中求解得 x = log2n 。所以上面代码的时间复杂度为 O(log2n)。 实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？ 因为对数之间是可以互相转换的，log3n = log32 log2n，所以 O(log3n) = O(C log2n)，其中 C=log32 是一个常量。 由于 时间复杂度 描述的是算法执行时间与数据规模的 增长变化趋势，所以 常量、低阶、系数 实际上对这种增长趋势不产生决定性影响，所以在做时间复杂度分析时 忽略 这些项。 因此，在对数阶时间复杂度的表示方法里，我们忽略对数的 “底”，统一表示为 O(logn)。 下面举例说明 O(nlogn)（对数阶）： function aFun(n){ let i = 1; while (i aFun 的时间复杂度为 O(logn)，而 cal 的时间复杂度为 O(n)，所以上面代码的时间复杂度为 T(n) = T1(logn) T2(n) = O(lognn) = O(nlogn) 。 非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。 包括 O(2n)（指数阶）、O(n!)（阶乘阶）。 O(2n)（指数阶）例子： aFunc( n ) { if (n 参考答案： 显然运行次数，T(0) = T(1) = 1，同时 T(n) = T(n - 1) + T(n - 2) + 1，这里的 1 是其中的加法算一次执行。 显然 T(n) = T(n - 1) + T(n - 2) 是一个斐波那契数列，通过归纳证明法可以证明，当 n >= 1 时 T(n) n，同时当 n > 4 时 T(n) >= (3/2)n。 所以该方法的时间复杂度可以表示为 O((5/3)n)，简化后为 O(2n)。 可见这个方法所需的运行时间是以指数的速度增长的。 如果大家感兴趣，可以试下分别用 1，10，100 的输入大小来测试下算法的运行时间，相信大家会感受到时间复杂度的无穷魅力。 3.5 时间复杂度分类 时间复杂度可以分为： 最好情况时间复杂度（best case time complexity）：在最理想的情况下，执行这段代码的时间复杂度。 最坏情况时间复杂度（worst case time complexity）：在最糟糕的情况下，执行这段代码的时间复杂度。 平均情况时间复杂度（average case time complexity），用代码在所有情况下执行的次数的加权平均值表示。也叫 加权平均时间复杂度 或者 期望时间复杂度。 均摊时间复杂度（amortized time complexity）: 在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。 举例说明： // n 表示数组 array 的长度 function find(array, n, x) { let i = 0; let pos = -1; for (; i find 函数实现的功能是在一个数组中找到值等于 x 的项，并返回索引值，如果没找到就返回 -1 。 最好情况时间复杂度，最坏情况时间复杂度 如果数组中第一个值就等于 x，那么时间复杂度为 O(1)，如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。 所以上面代码的 最好情况时间复杂度为 O(1)，最坏情况时间复杂度为 O(n)。 平均情况时间复杂度 如何分析平均时间复杂度 ？代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。 要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即： 省略掉系数、低阶、常量，所以，这个公式简化之后，得到的平均时间复杂度就是 O(n)。 我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。 因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样： 这个值就是概率论中的 加权平均值，也叫 期望值，所以平均时间复杂度的全称应该叫 加权平均时间复杂度 或者 期望时间复杂度。 所以，根据上面结论推导出，得到的 平均时间复杂度 仍然是 O(n)。 均摊时间复杂度 均摊时间复杂度就是一种特殊的平均时间复杂度 (应用场景非常特殊，非常有限，这里不说)。 3.6 时间复杂度总结 常用的时间复杂度所耗费的时间从小到大依次是： O(1) 2) 3) n) n) 常见的时间复杂度： 3.7 空间复杂度分析 时间复杂度的全称是 渐进时间复杂度，表示 算法的执行时间与数据规模之间的增长关系 。 类比一下，空间复杂度全称就是 渐进空间复杂度（asymptotic space complexity），表示 算法的存储空间与数据规模之间的增长关系 。 定义：算法的空间复杂度通过计算算法所需的存储空间实现，算法的空间复杂度的计算公式记作：S(n) = O(f(n))，其中，n 为问题的规模，f(n) 为语句关于 n 所占存储空间的函数。 function print(n) { const newArr = []; // 第 2 行 newArr.length = n; // 第 3 行 for (let i = 0; i = 0; --j) { console.log(newArr[i]) } } 跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 newArr ，是个空数组。第 3 行把 newArr 的长度修改为 n 的长度的数组，每项的值为 undefined ，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。 我们常见的空间复杂度就是 O(1)、O(n)、O(n2)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。 4. 如何掌握好复杂度分析方法 ？ 复杂度分析关键在于多练，所谓孰能生巧。 平时我们在写代码时，是用 空间换时间 还是 时间换空间，可以根据算法的时间复杂度和空间复杂度来衡量。 5. 最后 如果你觉得本文章或者项目对你有启发，请给个赞或者 star 吧，点赞是一种美德，谢谢。 笔者文章常更地址： 1. 微信公众号 2. github 3. 全栈修炼 参考文章： 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？ (数据结构)十分钟搞定算法时间复杂度 Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 22:44:38 "},"js-route.html":{"url":"js-route.html","title":"如何实现浏览器的前进与后退","keywords":"","body":" 复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半了。 1. 什么是复杂度分析 ？ 数据结构和算法解决是 “如何让计算机更快时间、更省空间的解决问题”。 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。 2. 为什么要进行复杂度分析 ？ 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。 3. 如何进行复杂度分析 ？ 3.1 大 O 表示法 算法的执行时间与每行代码的执行次数成正比，用 T(n) = O(f(n)) 表示，其中 T(n) 表示算法执行总时间，f(n) 表示每行代码执行总次数，而 n 往往表示数据的规模。这就是大 O 时间复杂度表示法。 3.2 时间复杂度 1）定义 算法的时间复杂度，也就是算法的时间量度。 大 O 时间复杂度表示法 实际上并不具体表示代码真正的执行时间，而是表示 代码执行时间随数据规模增长的变化趋势，所以也叫 渐进时间复杂度，简称 时间复杂度（asymptotic time complexity）。 例子1： function aFun() { console.log(\"Hello, World!\"); // 需要执行 1 次 return 0; // 需要执行 1 次 } 那么这个方法需要执行 2 次运算。 例子 2： function bFun(n) { for(let i = 0; i 那么这个方法需要执行 ( n + 1 + n + 1 ) = 2n +2 次运算。 例子 3： function cal(n) { let sum = 0; // 1 次 let i = 1; // 1 次 let j = 1; // 1 次 for (; i 注意，这里是二层 for 循环，所以第二层执行的是 n * n = n2 次，而且这里的循环是 ++i，和例子 2 的是 i++，是不同的，是先加与后加的区别。 那么这个方法需要执行 ( n2 + n2 + n + n + 1 + 1 +1 ) = 2n2 +2n + 3 。 2）特点 以时间复杂度为例，由于 时间复杂度 描述的是算法执行时间与数据规模的 增长变化趋势，所以 常量、低阶、系数 实际上对这种增长趋势不产生决定性影响，所以在做时间复杂度分析时 忽略 这些项。 所以，上面例子1 的时间复杂度为 T(n) = O(1)，例子2 的时间复杂度为 T(n) = O(n)，例子3 的时间复杂度为 T(n) = O(n2)。 3.3 时间复杂度分析 只关注循环执行次数最多的一段代码 单段代码看高频：比如循环。 function cal(n) { let sum = 0; let i = 1; for (; i 执行次数最多的是 for 循环及里面的代码，执行了 n 次，所以时间复杂度为 O(n)。 加法法则：总复杂度等于量级最大的那段代码的复杂度 多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 function cal(n) { let sum_1 = 0; let p = 1; for (; p 上面代码分为三部分，分别求 sum_1、sum_2、sum_3 ，主要看循环部分。 第一部分，求 sum_1 ，明确知道执行了 100 次，而和 n 的规模无关，是个常量的执行时间，不能反映增长变化趋势，所以时间复杂度为 O(1)。 第二和第三部分，求 sum_2 和 sum_3 ，时间复杂度是和 n 的规模有关的，为别为 O(n) 和 O(n2)。 所以，取三段代码的最大量级，上面例子的最终的时间复杂度为 O(n2)。 同理类推，如果有 3 层 for 循环，那么时间复杂度为 O(n3)，4 层就是 O(n4)。 所以，总的时间复杂度就等于量级最大的那段代码的时间复杂度。 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积 嵌套代码求乘积：比如递归、多重循环等。 function cal(n) { let ret = 0; let i = 1; for (; i 方法 cal 循环里面调用 f 方法，而 f 方法里面也有循环。 所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) T2(n) = O(nn) = O(n2) 。 多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加 function cal(m, n) { let sum_1 = 0; let i = 1; for (; i 以上代码也是求和 ，求 sum_1 的数据规模为 m、求 sum_2 的数据规模为 n，所以时间复杂度为 O(m+n)。 公式：T1(m) + T2(n) = O(f(m) + g(n)) 。 多个规模求乘法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相乘 function cal(m, n) { let sum_3 = 0; let i = 1; let j = 1; for (; i 以上代码也是求和，两层 for 循环 ，求 sum_3 的数据规模为 m 和 n，所以时间复杂度为 O(m*n)。 公式：T1(m) T2(n) = O(f(m) g(n)) 。 3.4 常用的时间复杂度分析 多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。 包括 O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n2) （平方阶）、O(n3)（立方阶）。 除了 O(logn)、O(nlogn) ，其他的都可从上面的几个例子中看到。 下面举例说明 O(logn)（对数阶）： let i=1; while (i 代码是从 1 开始，每次循环就乘以 2，当大于 n 时，循环结束。 其实就是高中学过的等比数列，i 的取值就是一个等比数列。在数学里面是这样子的： 20 21 22 ... 2k ... 2x = n 所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了，通过 2x = n 求解 x，数学中求解得 x = log2n 。所以上面代码的时间复杂度为 O(log2n)。 实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？ 因为对数之间是可以互相转换的，log3n = log32 log2n，所以 O(log3n) = O(C log2n)，其中 C=log32 是一个常量。 由于 时间复杂度 描述的是算法执行时间与数据规模的 增长变化趋势，所以 常量、低阶、系数 实际上对这种增长趋势不产生决定性影响，所以在做时间复杂度分析时 忽略 这些项。 因此，在对数阶时间复杂度的表示方法里，我们忽略对数的 “底”，统一表示为 O(logn)。 下面举例说明 O(nlogn)（对数阶）： function aFun(n){ let i = 1; while (i aFun 的时间复杂度为 O(logn)，而 cal 的时间复杂度为 O(n)，所以上面代码的时间复杂度为 T(n) = T1(logn) T2(n) = O(lognn) = O(nlogn) 。 非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。 包括 O(2n)（指数阶）、O(n!)（阶乘阶）。 O(2n)（指数阶）例子： aFunc( n ) { if (n 参考答案： 显然运行次数，T(0) = T(1) = 1，同时 T(n) = T(n - 1) + T(n - 2) + 1，这里的 1 是其中的加法算一次执行。 显然 T(n) = T(n - 1) + T(n - 2) 是一个斐波那契数列，通过归纳证明法可以证明，当 n >= 1 时 T(n) n，同时当 n > 4 时 T(n) >= (3/2)n。 所以该方法的时间复杂度可以表示为 O((5/3)n)，简化后为 O(2n)。 可见这个方法所需的运行时间是以指数的速度增长的。 如果大家感兴趣，可以试下分别用 1，10，100 的输入大小来测试下算法的运行时间，相信大家会感受到时间复杂度的无穷魅力。 3.5 时间复杂度分类 时间复杂度可以分为： 最好情况时间复杂度（best case time complexity）：在最理想的情况下，执行这段代码的时间复杂度。 最坏情况时间复杂度（worst case time complexity）：在最糟糕的情况下，执行这段代码的时间复杂度。 平均情况时间复杂度（average case time complexity），用代码在所有情况下执行的次数的加权平均值表示。也叫 加权平均时间复杂度 或者 期望时间复杂度。 均摊时间复杂度（amortized time complexity）: 在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。 举例说明： // n 表示数组 array 的长度 function find(array, n, x) { let i = 0; let pos = -1; for (; i find 函数实现的功能是在一个数组中找到值等于 x 的项，并返回索引值，如果没找到就返回 -1 。 最好情况时间复杂度，最坏情况时间复杂度 如果数组中第一个值就等于 x，那么时间复杂度为 O(1)，如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。 所以上面代码的 最好情况时间复杂度为 O(1)，最坏情况时间复杂度为 O(n)。 平均情况时间复杂度 如何分析平均时间复杂度 ？代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。 要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即： 省略掉系数、低阶、常量，所以，这个公式简化之后，得到的平均时间复杂度就是 O(n)。 我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。 因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样： 这个值就是概率论中的 加权平均值，也叫 期望值，所以平均时间复杂度的全称应该叫 加权平均时间复杂度 或者 期望时间复杂度。 所以，根据上面结论推导出，得到的 平均时间复杂度 仍然是 O(n)。 均摊时间复杂度 均摊时间复杂度就是一种特殊的平均时间复杂度 (应用场景非常特殊，非常有限，这里不说)。 3.6 时间复杂度总结 常用的时间复杂度所耗费的时间从小到大依次是： O(1) 2) 3) n) n) 常见的时间复杂度： 3.7 空间复杂度分析 时间复杂度的全称是 渐进时间复杂度，表示 算法的执行时间与数据规模之间的增长关系 。 类比一下，空间复杂度全称就是 渐进空间复杂度（asymptotic space complexity），表示 算法的存储空间与数据规模之间的增长关系 。 定义：算法的空间复杂度通过计算算法所需的存储空间实现，算法的空间复杂度的计算公式记作：S(n) = O(f(n))，其中，n 为问题的规模，f(n) 为语句关于 n 所占存储空间的函数。 function print(n) { const newArr = []; // 第 2 行 newArr.length = n; // 第 3 行 for (let i = 0; i = 0; --j) { console.log(newArr[i]) } } 跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 newArr ，是个空数组。第 3 行把 newArr 的长度修改为 n 的长度的数组，每项的值为 undefined ，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。 我们常见的空间复杂度就是 O(1)、O(n)、O(n2)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。 4. 如何掌握好复杂度分析方法 ？ 复杂度分析关键在于多练，所谓孰能生巧。 平时我们在写代码时，是用 空间换时间 还是 时间换空间，可以根据算法的时间复杂度和空间复杂度来衡量。 5. 最后 如果你觉得本文章或者项目对你有启发，请给个赞或者 star 吧，点赞是一种美德，谢谢。 笔者文章常更地址： 1. 微信公众号 2. github 3. 全栈修炼 参考文章： 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？ (数据结构)十分钟搞定算法时间复杂度 Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 22:44:45 "},"js-algorithms.html":{"url":"js-algorithms.html","title":"十大经典排序算法","keywords":"","body":" 1. 前言 算法为王。 想学好前端，先练好内功，内功不行，就算招式练的再花哨，终究成不了高手；只有内功深厚者，前端之路才会走得更远。 笔者写的 JavaScript 数据结构与算法之美 系列用的语言是 JavaScript ，旨在入门数据结构与算法和方便以后复习。 文中包含了 十大经典排序算法 的思想、代码实现、一些例子、复杂度分析、动画、还有算法可视化工具。 这应该是目前比较全的 JavaScript 十大经典排序算法 的讲解了吧。 2. 如何分析一个排序算法 复杂度分析是整个算法学习的精髓。 时间复杂度: 一个算法执行所耗费的时间。 空间复杂度: 运行完一个程序所需内存的大小。 时间和空间复杂度的详解，请看 JavaScript 数据结构与算法之美 - 时间和空间复杂度。 学习排序算法，我们除了学习它的算法原理、代码实现之外，更重要的是要学会如何评价、分析一个排序算法。 分析一个排序算法，要从 执行效率、内存消耗、稳定性 三方面入手。 2.1 执行效率 1. 最好情况、最坏情况、平均情况时间复杂度 我们在分析排序算法的时间复杂度时，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。 除此之外，你还要说出最好、最坏时间复杂度对应的要排序的原始数据是什么样的。 2. 时间复杂度的系数、常数 、低阶 我们知道，时间复杂度反应的是数据规模 n 很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。 但是实际的软件开发中，我们排序的可能是 10 个、100 个、1000 个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。 3. 比较次数和交换（或移动）次数 这一节和下一节讲的都是基于比较的排序算法。基于比较的排序算法的执行过程，会涉及两种操作，一种是元素比较大小，另一种是元素交换或移动。 所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。 2.2 内存消耗 也就是看空间复杂度。 还需要知道如下术语： 内排序：所有排序操作都在内存中完成； 外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行； 原地排序：原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。 2.3 稳定性 稳定：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 比如： a 原本在 b 前面，而 a = b，排序之后，a 仍然在 b 的前面； 不稳定：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序改变。 比如：a 原本在 b 的前面，而 a = b，排序之后， a 在 b 的后面； 3. 十大经典排序算法 3.1 冒泡排序（Bubble Sort） 思想 冒泡排序只会操作相邻的两个数据。 每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。 一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。 特点 优点：排序算法的基础，简单实用易于理解。 缺点：比较次数多，效率较低。 实现 // 冒泡排序（未优化） const bubbleSort = arr => { console.time('改进前冒泡排序耗时'); const length = arr.length; if (length arr[j + 1]) { const temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; } } } console.log('改进前 arr :', arr); console.timeEnd('改进前冒泡排序耗时'); }; 优化：当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。 // 冒泡排序（已优化） const bubbleSort2 = arr => { console.time('改进后冒泡排序耗时'); const length = arr.length; if (length arr[j + 1]) { const temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; hasChange = true; // 表示有数据交换 } } if (!hasChange) break; // 如果 false 说明所有元素已经到位，没有数据交换，提前退出 } console.log('改进后 arr :', arr); console.timeEnd('改进后冒泡排序耗时'); }; 测试 // 测试 const arr = [7, 8, 4, 5, 6, 3, 2, 1]; bubbleSort(arr); // 改进前 arr : [1, 2, 3, 4, 5, 6, 7, 8] // 改进前冒泡排序耗时: 0.43798828125ms const arr2 = [7, 8, 4, 5, 6, 3, 2, 1]; bubbleSort2(arr2); // 改进后 arr : [1, 2, 3, 4, 5, 6, 7, 8] // 改进后冒泡排序耗时: 0.318115234375ms 分析 第一，冒泡排序是原地排序算法吗 ？ 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。 第二，冒泡排序是稳定的排序算法吗 ？ 在冒泡排序中，只有交换才可以改变两个元素的前后顺序。 为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序。 所以冒泡排序是稳定的排序算法。 第三，冒泡排序的时间复杂度是多少 ？ 最佳情况：T(n) = O(n)，当数据已经是正序时。 最差情况：T(n) = O(n2)，当数据是反序时。 平均情况：T(n) = O(n2)。 动画 3.2 插入排序（Insertion Sort） 插入排序又为分为 直接插入排序 和优化后的 拆半插入排序 与 希尔排序，我们通常说的插入排序是指直接插入排序。 一、直接插入 思想 一般人打扑克牌，整理牌的时候，都是按牌的大小（从小到大或者从大到小）整理牌的，那每摸一张新牌，就扫描自己的牌，把新牌插入到相应的位置。 插入排序的工作原理：通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 步骤 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤 2 ~ 5。 实现 // 插入排序 const insertionSort = array => { const len = array.length; if (len = 0 && array[preIndex] > current) { //前置条件之一: 待比较元素比当前元素大 array[preIndex + 1] = array[preIndex]; //将待比较元素后移一位 preIndex--; //游标前移一位 } if (preIndex + 1 != i) { //避免同一个元素赋值给自身 array[preIndex + 1] = current; //将当前元素插入预留空位 console.log('array :', array); } } return array; }; 测试 // 测试 const array = [5, 4, 3, 2, 1]; console.log(\"原始 array :\", array); insertionSort(array); // 原始 array: [5, 4, 3, 2, 1] // array: [4, 5, 3, 2, 1] // array: [3, 4, 5, 2, 1] // array: [2, 3, 4, 5, 1] // array: [1, 2, 3, 4, 5] 分析 第一，插入排序是原地排序算法吗 ？ 插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，所以，这是一个原地排序算法。 第二，插入排序是稳定的排序算法吗 ？ 在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。 第三，插入排序的时间复杂度是多少 ？ 最佳情况：T(n) = O(n)，当数据已经是正序时。 最差情况：T(n) = O(n2)，当数据是反序时。 平均情况：T(n) = O(n2)。 动画 二、拆半插入 插入排序也有一种优化算法，叫做拆半插入。 思想 折半插入排序是直接插入排序的升级版，鉴于插入排序第一部分为已排好序的数组，我们不必按顺序依次寻找插入点，只需比较它们的中间值与待插入元素的大小即可。 步骤 取 0 ~ i-1 的中间点 ( m = (i-1) >> 1 )，array[i] 与 array[m] 进行比较，若 array[i] 重复步骤 1，每次缩小一半的查找范围，直至找到插入的位置。 将数组中插入位置之后的元素全部后移一位。 在指定位置插入第 i 个元素。 注：x >> 1 是位运算中的右移运算，表示右移一位，等同于 x 除以 2 再取整，即 x >> 1 == Math.floor(x/2) 。 // 折半插入排序 const binaryInsertionSort = array => { const len = array.length; if (len > 1; // 注: x>>1 是位运算中的右移运算, 表示右移一位, 等同于 x 除以 2 再取整, 即 x>>1 == Math.floor(x/2) . if (array[i] >= array[m]) { //值相同时, 切换到高半区，保证稳定性 low = m + 1; //插入点在高半区 } else { high = m - 1; //插入点在低半区 } } for (j = i; j > low; j--) { //步骤 3: 插入位置之后的元素全部后移一位 array[j] = array[j - 1]; console.log('array2 :', JSON.parse(JSON.stringify(array))); } array[low] = current; //步骤 4: 插入该元素 } console.log('array2 :', JSON.parse(JSON.stringify(array))); return array; }; 测试 const array2 = [5, 4, 3, 2, 1]; console.log('原始 array2:', array2); binaryInsertionSort(array2); // 原始 array2: [5, 4, 3, 2, 1] // array2 : [5, 5, 3, 2, 1] // array2 : [4, 5, 5, 2, 1] // array2 : [4, 4, 5, 2, 1] // array2 : [3, 4, 5, 5, 1] // array2 : [3, 4, 4, 5, 1] // array2 : [3, 3, 4, 5, 1] // array2 : [2, 3, 4, 5, 5] // array2 : [2, 3, 4, 4, 5] // array2 : [2, 3, 3, 4, 5] // array2 : [2, 2, 3, 4, 5] // array2 : [1, 2, 3, 4, 5] 注意：和直接插入排序类似，折半插入排序每次交换的是相邻的且值为不同的元素，它并不会改变值相同的元素之间的顺序，因此它是稳定的。 三、希尔排序 希尔排序是一个平均时间复杂度为 O(n log n) 的算法，会在下一个章节和 归并排序、快速排序、堆排序 一起讲，本文就不展开了。 3.3 选择排序（Selection Sort） 思路 选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。 步骤 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 实现 const selectionSort = array => { const len = array.length; let minIndex, temp; for (let i = 0; i 测试 // 测试 const array = [5, 4, 3, 2, 1]; console.log('原始array:', array); selectionSort(array); // 原始 array: [5, 4, 3, 2, 1] // array: [1, 4, 3, 2, 5] // array: [1, 2, 3, 4, 5] // array: [1, 2, 3, 4, 5] // array: [1, 2, 3, 4, 5] 分析 第一，选择排序是原地排序算法吗 ？ 选择排序空间复杂度为 O(1)，是一种原地排序算法。 第二，选择排序是稳定的排序算法吗 ？ 选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。所以，选择排序是一种不稳定的排序算法。 第三，选择排序的时间复杂度是多少 ？ 无论是正序还是逆序，选择排序都会遍历 n2 / 2 次来排序，所以，最佳、最差和平均的复杂度是一样的。 最佳情况：T(n) = O(n2)。 最差情况：T(n) = O(n2)。 平均情况：T(n) = O(n2)。 动画 3.4 归并排序（Merge Sort） 思想 排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。 归并排序采用的是分治思想。 分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。 注：x >> 1 是位运算中的右移运算，表示右移一位，等同于 x 除以 2 再取整，即 x >> 1 === Math.floor(x / 2) 。 实现 const mergeSort = arr => { //采用自上而下的递归方法 const len = arr.length; if (len > 1 和 Math.floor(len / 2) 等价 let middle = Math.floor(len / 2), left = arr.slice(0, middle), right = arr.slice(middle); // 拆分为两个子数组 return merge(mergeSort(left), mergeSort(right)); }; const merge = (left, right) => { const result = []; while (left.length && right.length) { // 注意: 判断的条件是小于或等于，如果只是小于，那么排序将不稳定. if (left[0] 测试 // 测试 const arr = [3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48]; console.time('归并排序耗时'); console.log('arr :', mergeSort(arr)); console.timeEnd('归并排序耗时'); // arr : [2, 3, 4, 5, 15, 19, 26, 27, 36, 38, 44, 46, 47, 48, 50] // 归并排序耗时: 0.739990234375ms 分析 第一，归并排序是原地排序算法吗 ？ 这是因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。 实际上，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。 所以，归并排序不是原地排序算法。 第二，归并排序是稳定的排序算法吗 ？ merge 方法里面的 left[0] 是稳定的排序方法。 第三，归并排序的时间复杂度是多少 ？ 从效率上看，归并排序可算是排序算法中的佼佼者。假设数组长度为 n，那么拆分数组共需 logn 步，又每步都是一个普通的合并子数组的过程，时间复杂度为 O(n)，故其综合时间复杂度为 O(n log n)。 最佳情况：T(n) = O(n log n)。 最差情况：T(n) = O(n log n)。 平均情况：T(n) = O(n log n)。 动画 3.5 快速排序 （Quick Sort） 快速排序的特点就是快，而且效率高！它是处理大数据最快的排序算法之一。 思想 先找到一个基准点（一般指数组的中部），然后数组被该基准点分为两部分，依次与该基准点数据比较，如果比它小，放左边；反之，放右边。 左右分别用一个空数组去存储比较后的数据。 最后递归执行上述操作，直到数组长度 特点：快速，常用。 缺点：需要另外声明两个数组，浪费了内存空间资源。 实现 方法一： const quickSort1 = arr => { if (arr.length 方法二： // 快速排序 const quickSort = (arr, left, right) => { let len = arr.length, partitionIndex; left = typeof left != 'number' ? 0 : left; right = typeof right != 'number' ? len - 1 : right; if (left { //分区操作 let pivot = left, //设定基准值（pivot） index = pivot + 1; for (let i = index; i { let temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }; 测试 // 测试 const array = [5, 4, 3, 2, 1]; console.log('原始array:', array); const newArr = quickSort(array); console.log('newArr:', newArr); // 原始 array: [5, 4, 3, 2, 1] // newArr: [1, 4, 3, 2, 5] 分析 第一，快速排序是原地排序算法吗 ？ 因为 partition() 函数进行分区时，不需要很多额外的内存空间，所以快排是原地排序算法。 第二，快速排序是稳定的排序算法吗 ？ 和选择排序相似，快速排序每次交换的元素都有可能不是相邻的，因此它有可能打破原来值为相同的元素之间的顺序。因此，快速排序并不稳定。 第三，快速排序的时间复杂度是多少 ？ 极端的例子：如果数组中的数据原来已经是有序的了，比如 1，3，5，6，8。如果我们每次选择最后一个元素作为 pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约 n 次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约 n / 2 个元素，这种情况下，快排的时间复杂度就从 O(nlogn) 退化成了 O(n2)。 最佳情况：T(n) = O(n log n)。 最差情况：T(n) = O(n2)。 平均情况：T(n) = O(n log n)。 动画 解答开篇问题 快排和归并用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢 ？ 可以发现： 归并排序的处理过程是由下而上的，先处理子问题，然后再合并。 而快排正好相反，它的处理过程是由上而下的，先分区，然后再处理子问题。 归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。 归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。 快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。 3.6 希尔排序（Shell Sort） 思想 先将整个待排序的记录序列分割成为若干子序列。 分别进行直接插入排序。 待整个序列中的记录基本有序时，再对全体记录进行依次直接插入排序。 过程 举个易于理解的例子：[35, 33, 42, 10, 14, 19, 27, 44]，我们采取间隔 4。创建一个位于 4 个位置间隔的所有值的虚拟子列表。下面这些值是 { 35, 14 }，{ 33, 19 }，{ 42, 27 } 和 { 10, 44 }。 我们比较每个子列表中的值，并在原始数组中交换它们（如果需要）。完成此步骤后，新数组应如下所示。 然后，我们采用 2 的间隔，这个间隙产生两个子列表：{ 14, 27, 35, 42 }， { 19, 10, 33, 44 }。 我们比较并交换原始数组中的值（如果需要）。完成此步骤后，数组变成：[14, 10, 27, 19, 35, 33, 42, 44]，图如下所示，10 与 19 的位置互换一下。 最后，我们使用值间隔 1 对数组的其余部分进行排序，Shell sort 使用插入排序对数组进行排序。 实现 const shellSort = arr => { let len = arr.length, temp, gap = 1; console.time('希尔排序耗时'); while (gap 0; gap = Math.floor(gap / 3)) { for (let i = gap; i = 0 && arr[j] > temp; j -= gap) { arr[j + gap] = arr[j]; } arr[j + gap] = temp; console.log('arr :', arr); } } console.timeEnd('希尔排序耗时'); return arr; }; 测试 // 测试 const array = [35, 33, 42, 10, 14, 19, 27, 44]; console.log('原始array:', array); const newArr = shellSort(array); console.log('newArr:', newArr); // 原始 array: [35, 33, 42, 10, 14, 19, 27, 44] // arr : [14, 33, 42, 10, 35, 19, 27, 44] // arr : [14, 19, 42, 10, 35, 33, 27, 44] // arr : [14, 19, 27, 10, 35, 33, 42, 44] // arr : [14, 19, 27, 10, 35, 33, 42, 44] // arr : [14, 19, 27, 10, 35, 33, 42, 44] // arr : [14, 19, 27, 10, 35, 33, 42, 44] // arr : [10, 14, 19, 27, 35, 33, 42, 44] // arr : [10, 14, 19, 27, 35, 33, 42, 44] // arr : [10, 14, 19, 27, 33, 35, 42, 44] // arr : [10, 14, 19, 27, 33, 35, 42, 44] // arr : [10, 14, 19, 27, 33, 35, 42, 44] // 希尔排序耗时: 3.592041015625ms // newArr: [10, 14, 19, 27, 33, 35, 42, 44] 分析 第一，希尔排序是原地排序算法吗 ？ 希尔排序过程中，只涉及相邻数据的交换操作，只需要常量级的临时空间，空间复杂度为 O(1) 。所以，希尔排序是原地排序算法。 第二，希尔排序是稳定的排序算法吗 ？ 我们知道，单次直接插入排序是稳定的，它不会改变相同元素之间的相对顺序，但在多次不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，可能导致相同元素相对顺序发生变化。 因此，希尔排序不稳定。 第三，希尔排序的时间复杂度是多少 ？ 最佳情况：T(n) = O(n log n)。 最差情况：T(n) = O(n log2 n)。 平均情况：T(n) = O(n log2 n)。 动画 3.7 堆排序（Heap Sort） 堆的定义 堆其实是一种特殊的树。只要满足这两点，它就是一个堆。 堆是一个完全二叉树。 完全二叉树：除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。 也可以说：堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。这两种表述是等价的。 对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作大顶堆。 对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作小顶堆。 其中图 1 和 图 2 是大顶堆，图 3 是小顶堆，图 4 不是堆。除此之外，从图中还可以看出来，对于同一组数据，我们可以构建多种不同形态的堆。 思想 将初始待排序关键字序列 (R1, R2 .... Rn) 构建成大顶堆，此堆为初始的无序区； 将堆顶元素 R[1] 与最后一个元素 R[n] 交换，此时得到新的无序区 (R1, R2, ..... Rn-1) 和新的有序区 (Rn) ，且满足 R[1, 2 ... n-1] 由于交换后新的堆顶 R[1] 可能违反堆的性质，因此需要对当前无序区 (R1, R2 ...... Rn-1) 调整为新堆，然后再次将 R[1] 与无序区最后一个元素交换，得到新的无序区 (R1, R2 .... Rn-2) 和新的有序区 (Rn-1, Rn)。不断重复此过程，直到有序区的元素个数为 n - 1，则整个排序过程完成。 实现 // 堆排序 const heapSort = array => { console.time('堆排序耗时'); // 初始化大顶堆，从第一个非叶子结点开始 for (let i = Math.floor(array.length / 2 - 1); i >= 0; i--) { heapify(array, i, array.length); } // 排序，每一次 for 循环找出一个当前最大值，数组长度减一 for (let i = Math.floor(array.length - 1); i > 0; i--) { // 根节点与最后一个节点交换 swap(array, 0, i); // 从根节点开始调整，并且最后一个结点已经为当前最大值，不需要再参与比较，所以第三个参数为 i，即比较到最后一个结点前一个即可 heapify(array, 0, i); } console.timeEnd('堆排序耗时'); return array; }; // 交换两个节点 const swap = (array, i, j) => { let temp = array[i]; array[i] = array[j]; array[j] = temp; }; // 将 i 结点以下的堆整理为大顶堆，注意这一步实现的基础实际上是： // 假设结点 i 以下的子堆已经是一个大顶堆，heapify 函数实现的 // 功能是实际上是：找到 结点 i 在包括结点 i 的堆中的正确位置。 // 后面将写一个 for 循环，从第一个非叶子结点开始，对每一个非叶子结点 // 都执行 heapify 操作，所以就满足了结点 i 以下的子堆已经是一大顶堆 const heapify = (array, i, length) => { let temp = array[i]; // 当前父节点 // j 测试 const array = [4, 6, 8, 5, 9, 1, 2, 5, 3, 2]; console.log('原始array:', array); const newArr = heapSort(array); console.log('newArr:', newArr); // 原始 array: [4, 6, 8, 5, 9, 1, 2, 5, 3, 2] // 堆排序耗时: 0.15087890625ms // newArr: [1, 2, 2, 3, 4, 5, 5, 6, 8, 9] 分析 第一，堆排序是原地排序算法吗 ？ 整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。 第二，堆排序是稳定的排序算法吗 ？ 因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。 所以，堆排序是不稳定的排序算法。 第三，堆排序的时间复杂度是多少 ？ 堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。 最佳情况：T(n) = O(n log n)。 最差情况：T(n) = O(n log n)。 平均情况：T(n) = O(n log n)。 动画 3.8 桶排序（Bucket Sort） 桶排序是计数排序的升级版，也采用了分治思想。 思想 将要排序的数据分到有限数量的几个有序的桶里。 每个桶里的数据再单独进行排序（一般用插入排序或者快速排序）。 桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 比如： 桶排序利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 为了使桶排序更加高效，我们需要做到这两点： 在额外空间充足的情况下，尽量增大桶的数量。 使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中。 桶排序的核心：就在于怎么把元素平均分配到每个桶里，合理的分配将大大提高排序的效率。 实现 // 桶排序 const bucketSort = (array, bucketSize) => { if (array.length === 0) { return array; } console.time('桶排序耗时'); let i = 0; let minValue = array[0]; let maxValue = array[0]; for (i = 1; i maxValue) { maxValue = array[i]; //输入数据的最大值 } } //桶的初始化 const DEFAULT_BUCKET_SIZE = 5; //设置桶的默认数量为 5 bucketSize = bucketSize || DEFAULT_BUCKET_SIZE; const bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1; const buckets = new Array(bucketCount); for (i = 0; i { let len = arr.length, partitionIndex; left = typeof left != 'number' ? 0 : left; right = typeof right != 'number' ? len - 1 : right; if (left { //分区操作 let pivot = left, //设定基准值（pivot） index = pivot + 1; for (let i = index; i { let temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; }; 测试 const array = [4, 6, 8, 5, 9, 1, 2, 5, 3, 2]; console.log('原始array:', array); const newArr = bucketSort(array); console.log('newArr:', newArr); // 原始 array: [4, 6, 8, 5, 9, 1, 2, 5, 3, 2] // 堆排序耗时: 0.133056640625ms // newArr: [1, 2, 2, 3, 4, 5, 5, 6, 8, 9] 分析 第一，桶排序是原地排序算法吗 ？ 因为桶排序的空间复杂度，也即内存消耗为 O(n)，所以不是原地排序算法。 第二，桶排序是稳定的排序算法吗 ？ 取决于每个桶的排序方式，比如：快排就不稳定，归并就稳定。 第三，桶排序的时间复杂度是多少 ？ 因为桶内部的排序可以有多种方法，是会对桶排序的时间复杂度产生很重大的影响。所以，桶排序的时间复杂度可以是多种情况的。 总的来说 最佳情况：当输入的数据可以均匀的分配到每一个桶中。 最差情况：当输入的数据被分配到了同一个桶中。 以下是桶的内部排序为快速排序的情况： 如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k =n / m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k logk)。 m 个桶排序的时间复杂度就是 O(m k logk)，因为 k = n / m，所以整个桶排序的时间复杂度就是 O(nlog(n/m))。 当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。 最佳情况：T(n) = O(n)。当输入的数据可以均匀的分配到每一个桶中。 最差情况：T(n) = O(nlogn)。当输入的数据被分配到了同一个桶中。 平均情况：T(n) = O(n)。 桶排序最好情况下使用线性时间 O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为 O(n)。 很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 适用场景 桶排序比较适合用在外部排序中。 外部排序就是数据存储在外部磁盘且数据量大，但内存有限，无法将整个数据全部加载到内存中。 动画 3.9 计数排序（Counting Sort） 思想 找出待排序的数组中最大和最小的元素。 统计数组中每个值为 i 的元素出现的次数，存入新数组 countArr 的第 i 项。 对所有的计数累加（从 countArr 中的第一个元素开始，每一项和前一项相加）。 反向填充目标数组：将每个元素 i 放在新数组的第 countArr[i] 项，每放一个元素就将 countArr[i] 减去 1 。 关键在于理解最后反向填充时的操作。 使用条件 只能用在数据范围不大的场景中，若数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序。 计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数。 比如如果考试成绩精确到小数后一位，就需要将所有分数乘以 10，转换为整数。 实现 方法一： const countingSort = array => { let len = array.length, result = [], countArr = [], min = (max = array[0]); console.time('计数排序耗时'); for (let i = 0; i = array[i] ? max : array[i]; countArr[array[i]] = countArr[array[i]] ? countArr[array[i]] + 1 : 1; } console.log('countArr :', countArr); // 从最小值 -> 最大值,将计数逐项相加 for (let j = min; j = 0; k--) { // result[位置] = array 数据 result[countArr[array[k]] - 1] = array[k]; // 减少 countArr 数组中保存的计数 countArr[array[k]]--; // console.log(\"array[k]:\", array[k], 'countArr[array[k]] :', countArr[array[k]],) console.log('result:', result); } console.timeEnd('计数排序耗时'); return result; }; 测试 const array = [2, 2, 3, 8, 7, 1, 2, 2, 2, 7, 3, 9, 8, 2, 1, 4, 2, 4, 6, 9, 2]; console.log('原始 array: ', array); const newArr = countingSort(array); console.log('newArr: ', newArr); // 原始 array: [2, 2, 3, 8, 7, 1, 2, 2, 2, 7, 3, 9, 8, 2, 1, 4, 2, 4, 6, 9, 2] // 计数排序耗时: 5.6708984375ms // newArr: [1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 6, 7, 7, 8, 8, 9, 9] 方法二： const countingSort2 = (arr, maxValue) => { console.time('计数排序耗时'); maxValue = maxValue || arr.length; let bucket = new Array(maxValue + 1), sortedIndex = 0; (arrLen = arr.length), (bucketLen = maxValue + 1); for (let i = 0; i 0) { arr[sortedIndex++] = j; bucket[j]--; } } console.timeEnd('计数排序耗时'); return arr; }; 测试 const array2 = [2, 2, 3, 8, 7, 1, 2, 2, 2, 7, 3, 9, 8, 2, 1, 4, 2, 4, 6, 9, 2]; console.log('原始 array2: ', array2); const newArr2 = countingSort2(array2, 21); console.log('newArr2: ', newArr2); // 原始 array: [2, 2, 3, 8, 7, 1, 2, 2, 2, 7, 3, 9, 8, 2, 1, 4, 2, 4, 6, 9, 2] // 计数排序耗时: 0.043212890625ms // newArr: [1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 6, 7, 7, 8, 8, 9, 9] 例子 可以认为，计数排序其实是桶排序的一种特殊情况。 当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。 我们都经历过高考，高考查分数系统你还记得吗？我们查分数的时候，系统会显示我们的成绩以及所在省的排名。如果你所在的省有 50 万考生，如何通过成绩快速排序得出名次呢？ 考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以我们可以分成 901 个桶，对应分数从 0 分到 900 分。 根据考生的成绩，我们将这 50 万考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。 我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。 因为只涉及扫描遍历操作，所以时间复杂度是 O(n)。 分析 第一，计数排序是原地排序算法吗 ？ 因为计数排序的空间复杂度为 O(k)，k 桶的个数，所以不是原地排序算法。 第二，计数排序是稳定的排序算法吗 ？ 计数排序不改变相同元素之间原本相对的顺序，因此它是稳定的排序算法。 第三，计数排序的时间复杂度是多少 ？ 最佳情况：T(n) = O(n + k) 最差情况：T(n) = O(n + k) 平均情况：T(n) = O(n + k) k 是待排序列最大值。 动画 3.10 基数排序（Radix Sort） 思想 基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。 例子 假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，你有什么比较快速的排序方法呢 ？ 这个问题里有这样的规律：假设要比较两个手机号码 a，b 的大小，如果在前面几位中，a 手机号码已经比 b 手机号码大了，那后面的几位就不用看了。所以是基于位来比较的。 桶排序、计数排序能派上用场吗 ？手机号码有 11 位，范围太大，显然不适合用这两种排序算法。针对这个排序问题，有没有时间复杂度是 O(n) 的算法呢 ？ 有，就是基数排序。 使用条件 要求数据可以分割独立的位来比较； 位之间由递进关系，如果 a 数据的高位比 b 数据大，那么剩下的地位就不用比较了； 每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到 O(n)。 方案 按照优先从高位或低位来排序有两种实现方案: MSD：由高位为基底，先按 k1 排序分组，同一组中记录, 关键码 k1 相等，再对各组按 k2 排序分成子组, 之后，对后面的关键码继续这样的排序分组，直到按最次位关键码 kd 对各子组排序后，再将各组连接起来，便得到一个有序序列。MSD 方式适用于位数多的序列。 LSD：由低位为基底，先从 kd 开始排序，再对 kd - 1 进行排序，依次重复，直到对 k1 排序后便得到一个有序序列。LSD 方式适用于位数少的序列。 实现 /** * name: 基数排序 * @param array 待排序数组 * @param max 最大位数 */ const radixSort = (array, max) => { console.time('计数排序耗时'); const buckets = []; let unit = 10, base = 1; for (let i = 0; i 测试 const array = [3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48]; console.log('原始array:', array); const newArr = radixSort(array, 2); console.log('newArr:', newArr); // 原始 array: [3, 44, 38, 5, 47, 15, 36, 26, 27, 2, 46, 4, 19, 50, 48] // 堆排序耗时: 0.064208984375ms // newArr: [2, 3, 4, 5, 15, 19, 26, 27, 36, 38, 44, 46, 47, 48, 50] 分析 第一，基数排序是原地排序算法吗 ？ 因为计数排序的空间复杂度为 O(n + k)，所以不是原地排序算法。 第二，基数排序是稳定的排序算法吗 ？ 基数排序不改变相同元素之间的相对顺序，因此它是稳定的排序算法。 第三，基数排序的时间复杂度是多少 ？ 最佳情况：T(n) = O(n k) 最差情况：T(n) = O(n k) 平均情况：T(n) = O(n * k) 其中，k 是待排序列最大值。 动画 LSD 基数排序动图演示： 4. 复杂度对比 十大经典排序算法的 时间复杂度与空间复杂度 比较。 名称 平均 最好 最坏 空间 稳定性 排序方式 冒泡排序 O(n2) O(n) O(n2) O(1) Yes In-place 插入排序 O(n2) O(n) O(n2) O(1) Yes In-place 选择排序 O(n2) O(n2) O(n2) O(1) No In-place 归并排序 O(n log n) O(n log n) O(n log n) O(n) Yes Out-place 快速排序 O(n log n) O(n log n) O(n2) O(logn) No In-place 希尔排序 O(n log n) O(n log2 n) O(n log2 n) O(1) No In-place 堆排序 O(n log n) O(n log n) O(n log n) O(1) No In-place 桶排序 O(n + k) O(n + k) O(n2) O(n + k) Yes Out-place 计数排序 O(n + k) O(n + k) O(n + k) O(k) Yes Out-place 基数排序 O(n * k) O(n * k) O(n * k) O(n + k) Yes Out-place 名词解释： n：数据规模； k：桶的个数； In-place: 占用常数内存，不占用额外内存； Out-place: 占用额外内存。 5. 算法可视化工具 算法可视化工具 algorithm-visualizer 算法可视化工具 algorithm-visualizer 是一个交互式的在线平台，可以从代码中可视化算法，还可以看到代码执行的过程。旨在通过交互式可视化的执行来揭示算法背后的机制。 效果如下图： 算法可视化动画网站 https://visualgo.net/en 效果如下图： 算法可视化动画网站 www.ee.ryerson.ca 效果如下图： illustrated-algorithms 变量和操作的可视化表示增强了控制流和实际源代码。您可以快速前进和后退执行，以密切观察算法的工作方式。 效果如下图： 6. 系列文章 JavaScript 数据结构与算法之美 系列文章，暂时写了如下的 11 篇文章，后续还有想写的内容，再补充。 所写的内容只是数据结构与算法内容的冰山一角，如果你还想学更多的内容，推荐学习王争老师的 数据结构与算法之美。 从时间和空间复杂度、基础数据结构到排序算法，文章的内容有一定的关联性，所以阅读时推荐按顺序来阅读，效果更佳。 1. JavaScript 数据结构与算法之美 - 时间和空间复杂度 2. JavaScript 数据结构与算法之美 - 线性表（数组、队列、栈、链表） 3. JavaScript 数据结构与算法之美 - 实现一个前端路由，如何实现浏览器的前进与后退 ？ 4. JavaScript 数据结构与算法之美 - 栈内存与堆内存 、浅拷贝与深拷贝 5. JavaScript 数据结构与算法之美 - 递归 6. JavaScript 数据结构与算法之美 - 非线性表（树、堆） 7. JavaScript 数据结构与算法之美 - 冒泡排序、选择排序、插入排序 8. JavaScript 数据结构与算法之美 - 归并排序、快速排序、希尔排序、堆排序 9. JavaScript 数据结构与算法之美 - 计数排序、桶排序、基数排序 10. JavaScript 数据结构与算法之美 - 十大经典排序算法汇总 11. JavaScript 数据结构与算法之美 - 强烈推荐 GitHub 上值得前端学习的数据结构与算法项目 如果有错误或者不严谨的地方，请务必给予指正，以免误人子弟，十分感谢。 7. 最后 文中所有的代码及测试事例都已经放到我的 GitHub 上了。 笔者为了写好这系列的文章，花费了大量的业余时间，边学边写，边写边修改，前后历时差不多 2 个月，入门级的文章总算是写完了。 如果你觉得有用或者喜欢，就点收藏，顺便点个赞吧，你的支持是我最大的鼓励 ！ Copyright © biaochenxuying.cn 2019 all right reserved，powered by Gitbook该文件修订时间： 2019-11-15 22:45:01 "}}